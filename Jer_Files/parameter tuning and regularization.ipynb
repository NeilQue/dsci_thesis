{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 Train 2022 H1 Val H2 Test Time Forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from random import seed\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Number Seed\n",
    "keras.utils.set_random_seed(30)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2021-2022 data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "test = df[int(n*0.75):]\n",
    "test_dates = test['datetime']\n",
    "test_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Waterlevel_Sto_Nino', 'Rainfall_Aries', 'Rainfall_Boso', 'Rainfall_Campana', 'Rainfall_Nangka', 'Rainfall_Oro']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "train_df = df[0:int(n*0.5)]\n",
    "val_df = df[int(n*0.5):int(n*0.75)]\n",
    "test_df = df[int(n*0.75):]\n",
    "\n",
    "num_features = df.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "          data=data,\n",
    "          targets=None,\n",
    "          sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=True,\n",
    "          batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    # properties to access them as tf datasets\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "            # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "            # And cache it for next time\n",
    "            self._example = result\n",
    "        return result\n",
    "\n",
    "    def plot(self, model=None, plot_col='Waterlevel_Sto_Nino', max_subplots=3):\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col}')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Time [h]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(input_width = 6, label_width = 6, shift = 1, label_columns = ['Waterlevel_Sto_Nino'])\n",
    "wide_window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for the number of units\n",
    "1. Number of dense layers - 2 to 5\n",
    "2. Number of units per layer - 16 to 128 (step = 16)\n",
    "3. Type of activation function - relu or tanh or sigmoid\n",
    "4. Penalty of L2 Regularisation - lambda = 0.001, 0.0005, 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model_names = []\n",
    "dnn_list_of_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Neural Network\n",
    "def dense_model(no_of_layers, no_of_units, acti, penalty):\n",
    "    model_name = f'Dense_{no_of_layers}_{no_of_units}_{activation}_{penalty}'\n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(no_of_layers):\n",
    "        model.add(layers.Dense(units = no_of_units, activation = acti, kernel_regularizer=regularizers.l2(penalty)))\n",
    "    model.add(layers.Dense(units = 1))\n",
    "    \n",
    "    return model_name, model\n",
    "\n",
    "for no_of_layers in range(2,6):\n",
    "    for no_of_units in range(16,129,16):\n",
    "        for activation in ['relu', 'tanh', 'sigmoid']:\n",
    "            for penalty in [0.001, 0.0005, 0.0001]:\n",
    "                model_name, model = dense_model(no_of_layers, no_of_units, activation, penalty)\n",
    "                dnn_model_names.append(model_name)\n",
    "                dnn_list_of_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.square(K.sum(xm * ym))\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = (x_square_sum * y_square_sum) + K.epsilon()\n",
    "    \n",
    "    r = r_num / r_den\n",
    "    return r\n",
    "def NSE(y_true, y_pred):\n",
    "    '''\n",
    "    This is the Nash-Sutcliffe Efficiency Coefficient\n",
    "    '''\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "\n",
    "    \n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError(), r_square, NSE])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_val_performance = {}\n",
    "dnn_history = {}\n",
    "for count, model in enumerate(dnn_list_of_models):\n",
    "    model_name = dnn_model_names[count]\n",
    "    dnn_history[model_name] = compile_and_fit(model, wide_window)\n",
    "    dense_val_performance[model_name] = model.evaluate(wide_window.val, return_dict = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_val_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_models = pd.DataFrame.from_dict(dense_val_performance)\n",
    "dense_models = dense_models.transpose()\n",
    "dense_models = dense_models.sort_values(by = \"loss\")\n",
    "dense_models = dense_models.reset_index()\n",
    "dense_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate the best model according to least validation loss\n",
    "# Constructing the best model\n",
    "best_dnn_index = dense_models['loss'].idxmin()\n",
    "best_dnn_model = dnn_list_of_models[best_dnn_index]\n",
    "performance['Dense'] = best_dnn_model.evaluate(wide_window.test, verbose = 0, return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Overfitting \n",
    "dnn_name = dnn_model_names[best_dnn_index]\n",
    "dense_history = dnn_history[dnn_name].history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(dense_history['loss'])\n",
    "plt.plot(dense_history['val_loss'])\n",
    "plt.title('DNN Model Loss Learning Curve (1st Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dense_history['loss']\n",
    "dvh = dense_history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dh[1:]\n",
    "dvh = dvh[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_n = len(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.linspace(1,dnn_n, dnn_n), dh)\n",
    "plt.plot(np.linspace(1,dnn_n, dnn_n), dvh)\n",
    "plt.title('DNN Model Loss Learning Curve (1st Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_history_2 = compile_and_fit(best_dnn_model, wide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(dense_history_2.history['loss'])\n",
    "plt.plot(dense_history_2.history['val_loss'])\n",
    "plt.title('DNN Model Loss Learning Curve (2nd Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_predictions = best_dnn_model.predict(test_df)\n",
    "actual = test_df['Waterlevel_Sto_Nino']\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates  # Import the dates module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))  # Adjust the width and height as needed\n",
    "plt.plot(test_dates, dense_predictions, c = \"blue\", label = \"predictions\", alpha = 0.5)\n",
    "plt.plot(test_dates, actual, c = \"red\", label = \"actual\", alpha = 0.5)\n",
    "plt.title('Predictions vs Actual Values (DNN Test Set) - 2nd Half of 2022')\n",
    "plt.ylabel('Water Level Sto Nino (meters)')\n",
    "plt.xlabel('Datetime')\n",
    "\n",
    "# Set x-axis major locator to show ticks for every month\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "# Format the dates as YYYY-MM-DD\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.gca().xaxis_date()\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Number Seed\n",
    "keras.utils.set_random_seed(30)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual.idxmax()\n",
    "actual[15193]\n",
    "max(dense_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_names = []\n",
    "cnn_list_of_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Neural Network (CNN)\n",
    "CONV_WIDTH = 6\n",
    "\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=['Waterlevel_Sto_Nino'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Neural Network (CNN)\n",
    "def cnn_model(no_of_layers, no_of_units, acti, penalty):\n",
    "    model_name = f'CNN_{no_of_layers}_{no_of_units}_{activation}_{penalty}'\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv1D(filters = 64, kernel_size =(CONV_WIDTH,), activation = acti, kernel_regularizer = regularizers.l2(penalty)))\n",
    "    for i in range(no_of_layers):\n",
    "        model.add(layers.Dense(units = no_of_units, activation = acti, kernel_regularizer = regularizers.l2(penalty)))\n",
    "    model.add(layers.Dense(units = 1))\n",
    "    \n",
    "    return model_name, model\n",
    "\n",
    "for no_of_layers in range(2,6):\n",
    "    for no_of_units in range(16,129,16):\n",
    "        for activation in ['relu', 'tanh', 'sigmoid']:\n",
    "            for penalty in [0.001, 0.0005, 0.0001]:\n",
    "                model_name, model = cnn_model(no_of_layers, no_of_units, activation, penalty)\n",
    "                cnn_model_names.append(model_name)\n",
    "                cnn_list_of_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_val_performance = {}\n",
    "cnn_history = {}\n",
    "for count, model in enumerate(cnn_list_of_models):\n",
    "    model_name = cnn_model_names[count]\n",
    "    cnn_history[model_name] = compile_and_fit(model, conv_window)\n",
    "    cnn_val_performance[model_name] = model.evaluate(conv_window.val, return_dict = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_models = pd.DataFrame.from_dict(cnn_val_performance)\n",
    "cnn_models = cnn_models.transpose()\n",
    "cnn_models = cnn_models.sort_values(by = 'loss')\n",
    "cnn_models = cnn_models.reset_index()\n",
    "cnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the best performing model that has the least validation loss\n",
    "best_cnn_index = cnn_models['loss'].idxmin()\n",
    "best_cnn_model = cnn_list_of_models[best_cnn_index]\n",
    "performance['CNN'] = best_cnn_model.evaluate(conv_window.test, verbose = 0, return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Overfitting CNN \n",
    "cnn_name = cnn_model_names[best_cnn_index]\n",
    "conv_history = cnn_history[cnn_name].history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(conv_history['loss'])\n",
    "plt.plot(conv_history['val_loss'])\n",
    "plt.title('CNN Model Loss Learning Curve (1st Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = conv_history['loss']\n",
    "cvh = conv_history['val_loss']\n",
    "ch = ch[1:]\n",
    "cvh = cvh[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_n = len(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.linspace(1,cnn_n, cnn_n), ch)\n",
    "plt.plot(np.linspace(1,cnn_n, cnn_n), cvh)\n",
    "plt.title('CNN Model Loss Learning Curve (1st Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_history_2 = compile_and_fit(best_cnn_model, conv_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(conv_history_2.history['loss'])\n",
    "plt.plot(conv_history_2.history['val_loss'])\n",
    "plt.title('CNN Model Loss Learning Curve (2nd Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = test_df.values.reshape(1, -1, CONV_WIDTH)  # Add batch dimension of 1\n",
    "conv_predictions = best_cnn_model.predict(prediction_data)\n",
    "actual = test_df['Waterlevel_Sto_Nino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the conv_predictions array\n",
    "# delete the first 5 values of the actual and test_dates arrays (corresponding to t = 0 to 4)\n",
    "\n",
    "conv_predictions = conv_predictions.reshape(4375)\n",
    "actual = actual[5:]\n",
    "test_dates_cnn = test_dates[5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates  # Import the dates module\n",
    "\n",
    "plt.figure(figsize=(14, 9))  # Adjust the width and height as needed\n",
    "plt.plot(test_dates_cnn, conv_predictions, c = \"blue\", label = \"predictions\", alpha = 0.5)\n",
    "plt.plot(test_dates_cnn, actual, c = \"red\", label = \"actual\", alpha = 0.5)\n",
    "plt.title('Predictions vs Actual Values (CNN Test Set) - 2nd Half of 2022')\n",
    "plt.ylabel('Water Level Sto Nino (meters)')\n",
    "plt.xlabel('Datetime')\n",
    "\n",
    "# Set x-axis major locator to show ticks for every month\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "# Format the dates as YYYY-MM-DD\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.gca().xaxis_date()\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Number Seed\n",
    "keras.utils.set_random_seed(30)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_names = []\n",
    "lstm_list_of_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM / RNN\n",
    "\n",
    "# Dense Neural Network\n",
    "def lstm_model(no_of_layers, no_of_units, acti, penalty):\n",
    "    model_name = f'LSTM_{no_of_layers}_{no_of_units}_{activation}_{penalty}'\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(64, return_sequences = True, kernel_regularizer = regularizers.l2(penalty)))\n",
    "    for i in range(no_of_layers):\n",
    "        model.add(layers.Dense(units = no_of_units, activation = acti, kernel_regularizer = regularizers.l2(penalty)))\n",
    "    model.add(layers.Dense(units = 1))\n",
    "    \n",
    "    return model_name, model\n",
    "\n",
    "for no_of_layers in range(2,6):\n",
    "    for no_of_units in range(16,129,16):\n",
    "        for activation in ['relu', 'tanh', 'sigmoid']:\n",
    "            for penalty in [0.001, 0.0005, 0.0001]:\n",
    "                model_name, model = lstm_model(no_of_layers, no_of_units, activation, penalty)\n",
    "                lstm_model_names.append(model_name)\n",
    "                lstm_list_of_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_val_performance = {}\n",
    "lstm_history = {}\n",
    "for count, model in enumerate(lstm_list_of_models):\n",
    "    model_name = lstm_model_names[count]\n",
    "    lstm_history[model_name] = compile_and_fit(model, wide_window)\n",
    "    lstm_val_performance[model_name] = model.evaluate(wide_window.val, return_dict = True)\n",
    "print(lstm_val_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_models = pd.DataFrame.from_dict(lstm_val_performance)\n",
    "lstm_models = lstm_models.transpose()\n",
    "lstm_models = lstm_models.sort_values(by = \"loss\")\n",
    "lstm_models = lstm_models.reset_index()\n",
    "lstm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate the best model according to least validation loss\n",
    "# Constructing the best model\n",
    "best_lstm_index = lstm_models['loss'].idxmin()\n",
    "best_lstm_model = lstm_list_of_models[best_lstm_index]\n",
    "performance['LSTM'] = best_lstm_model.evaluate(wide_window.test, verbose = 0, return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Overfitting LSTM \n",
    "lstm_name = lstm_model_names[best_lstm_index]\n",
    "long_history = lstm_history[lstm_name].history\n",
    "long_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(long_history['loss'])\n",
    "plt.plot(long_history['val_loss'])\n",
    "plt.title('LSTM Model Loss Learning Curve (1st Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh = long_history['loss']\n",
    "lvh = long_history['val_loss']\n",
    "lh = lh[1:]\n",
    "lvh = lvh[1:]\n",
    "lnn_n = len(lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.linspace(1,lnn_n, lnn_n), lh)\n",
    "plt.plot(np.linspace(1,lnn_n, lnn_n), lvh)\n",
    "plt.title('LSTM Model Loss Learning Curve (1st Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_history_2 = compile_and_fit(best_lstm_model, wide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(long_history_2.history['loss'])\n",
    "plt.plot(long_history_2.history['val_loss'])\n",
    "plt.title('LSTM Model Loss Learning Curve (2nd Training Process)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = test_df.values.reshape(1, -1, 6)  # Add batch dimension of 1\n",
    "lstm_predictions = best_lstm_model.predict(prediction_data)\n",
    "actual = test_df['Waterlevel_Sto_Nino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_predictions.shape)\n",
    "lstm_predictions = lstm_predictions.reshape(4380)\n",
    "print(actual.shape)\n",
    "print(lstm_predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates  # Import the dates module\n",
    "\n",
    "plt.figure(figsize=(14, 9))  # Adjust the width and height as needed\n",
    "plt.plot(test_dates, lstm_predictions, c = \"blue\", label = \"predictions\", alpha = 0.5)\n",
    "plt.plot(test_dates, actual, c = \"red\", label = \"actual\", alpha = 0.5)\n",
    "plt.title('Predictions vs Actual Values (LSTM Test Set) - 2nd Half of 2022')\n",
    "plt.ylabel('Water Level Sto Nino (meters)')\n",
    "plt.xlabel('Datetime')\n",
    "\n",
    "# Set x-axis major locator to show ticks for every month\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "# Format the dates as YYYY-MM-DD\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.gca().xaxis_date()\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lstm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(performance).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions (starting from t = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates_cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dense_predictions.shape)\n",
    "dense_predictions = dense_predictions.reshape(4380)\n",
    "\n",
    "print(conv_predictions.shape)\n",
    "print(lstm_predictions.shape)\n",
    "dense_predictions\n",
    "dense_predictions = dense_predictions[5:]\n",
    "lstm_predictions = lstm_predictions[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = actual[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual.shape)\n",
    "print(dense_predictions.shape)\n",
    "print(conv_predictions.shape)\n",
    "print(lstm_predictions.shape)\n",
    "print(test_dates_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'datetime': test_dates_cnn.tolist(),\n",
    "    'actual': actual.tolist(),\n",
    "    'dense_predictions': dense_predictions.tolist(),\n",
    "    'conv_predictions': conv_predictions.tolist(),\n",
    "    'lstm_predictions': lstm_predictions.tolist()\n",
    "}\n",
    "\n",
    "predictions = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions['actual'] == 18.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('2H 2022 Predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-step models\n",
    "- Uses the past 24 hours of data to predict the water level 24 hours into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_STEPS = 24\n",
    "multistep_window = WindowGenerator(input_width=24,\n",
    "                               label_width=OUT_STEPS,\n",
    "                               shift=OUT_STEPS)\n",
    "\n",
    "multistep_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_val_performance = {}\n",
    "multi_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive model : decomposes the prediction into individual time steps, you use the output for the next prediction\n",
    "# Autoregressive LSTM/RNN\n",
    "\n",
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(6)\n",
    "    def warmup(self, inputs):\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "        return prediction, state\n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "        # Initialize the LSTM state.\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps.\n",
    "        for n in range(1, self.out_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "            # Add the prediction to the output.\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        print(predictions)\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        print(predictions)\n",
    "        return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)\n",
    "prediction, state = feedback_model.warmup(multistep_window.example[0])\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Output shape (batch, time, features): ', feedback_model(multistep_window.example[0]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(feedback_model, multistep_window)\n",
    "\n",
    "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multistep_window.val, return_dict=True)\n",
    "multi_performance['AR LSTM'] = feedback_model.evaluate(multistep_window.test, verbose=0, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = test_df.values.reshape(1, -1, 6)  # Add batch dimension of 1\n",
    "ar_lstm_predictions = feedback_model.predict(prediction_data)\n",
    "actual = test_df['Waterlevel_Sto_Nino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_lstm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
