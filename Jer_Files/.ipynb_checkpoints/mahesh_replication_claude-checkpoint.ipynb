{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# import tensorboard\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "best_model = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "layer_1_neurons = [16,32,64]   ######## Check the number of neurons ########\n",
    "layer_2_neurons = [16,32,64]  ######## Check the number of neurons ########\n",
    "layer_3_neurons = [16,32,64]  ######## Check the number of neurons ########\n",
    "reg_consts = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.square(K.sum(xm * ym))\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = (x_square_sum * y_square_sum) + K.epsilon()\n",
    "    \n",
    "    r = r_num / r_den\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NSE(y_true, y_pred):\n",
    "\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    y_true = K.flatten(y_true)\n",
    "\n",
    "    \n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDE Loss Function\n",
    "def custom_loss(grads_inputs):\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = grads_inputs[:,0], grads_inputs[:,1], grads_inputs[:,2], grads_inputs[:,3], grads_inputs[:,4]\n",
    "    g = K.constant(9.8)\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        loss_saint_venant = du_dt + y_pred[:,0] * du_dx + g*dh_dx + g*slope + g*K.square(fric_coeff) * K.square(y_true[:,0])/(K.pow(y_true[:,1], 4/3) + K.epsilon())\n",
    "        l = K.mean(K.square(loss_saint_venant))\n",
    "\n",
    "        return 2*l+ K.sum(K.mean(K.square(y_pred - y_true), axis=0))\n",
    "   \n",
    "    # Return a function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined 2016-2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Rainfall_Aries</th>\n",
       "      <th>Rainfall_Boso</th>\n",
       "      <th>Rainfall_Campana</th>\n",
       "      <th>Rainfall_Nangka</th>\n",
       "      <th>Rainfall_Oro</th>\n",
       "      <th>Waterlevel_Sto_Nino</th>\n",
       "      <th>Waterlevel_Montalban</th>\n",
       "      <th>Discharge_Sto_Nino</th>\n",
       "      <th>Discharge_San_Jose</th>\n",
       "      <th>Cross_Section_Sto_Nino</th>\n",
       "      <th>Cross_Section_Montalban</th>\n",
       "      <th>Velocity_Sto_Nino</th>\n",
       "      <th>Velocity_Montalban</th>\n",
       "      <th>datetime</th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.18</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.033407</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>803.88</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026165</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.280072</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>804.54</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.19</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.280072</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>804.54</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.529056</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>805.20</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.529056</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>805.20</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>17515</td>\n",
       "      <td>16059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 19:00:00</td>\n",
       "      <td>63140400.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17516</th>\n",
       "      <td>17516</td>\n",
       "      <td>16424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>63144000.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17517</th>\n",
       "      <td>17517</td>\n",
       "      <td>16789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>63147600.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17518</th>\n",
       "      <td>17518</td>\n",
       "      <td>17154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>63151200.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17519</th>\n",
       "      <td>17519</td>\n",
       "      <td>17519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>63154800.0</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index  Rainfall_Aries  Rainfall_Boso  Rainfall_Campana  \\\n",
       "0               0      0               0              1                 2   \n",
       "1               1      1               0              1                 1   \n",
       "2               2      2               1              1                 1   \n",
       "3               3      3               0              0                 0   \n",
       "4               4      4               1              1                 1   \n",
       "...           ...    ...             ...            ...               ...   \n",
       "17515       17515  16059               0              0                 0   \n",
       "17516       17516  16424               0              0                 0   \n",
       "17517       17517  16789               0              0                 0   \n",
       "17518       17518  17154               0              0                 0   \n",
       "17519       17519  17519               0              0                 0   \n",
       "\n",
       "       Rainfall_Nangka  Rainfall_Oro  Waterlevel_Sto_Nino  \\\n",
       "0                    0             0                12.18   \n",
       "1                    1             0                12.19   \n",
       "2                    0             1                12.19   \n",
       "3                    1             0                12.20   \n",
       "4                    0             0                12.20   \n",
       "...                ...           ...                  ...   \n",
       "17515                0             0                12.44   \n",
       "17516                0             0                12.44   \n",
       "17517                0             0                12.44   \n",
       "17518                0             0                12.44   \n",
       "17519                0             0                12.44   \n",
       "\n",
       "       Waterlevel_Montalban  Discharge_Sto_Nino  Discharge_San_Jose  \\\n",
       "0                     21.03           21.033407           14.842428   \n",
       "1                     21.03           21.280072           14.842428   \n",
       "2                     21.03           21.280072           14.842428   \n",
       "3                     21.03           21.529056           14.842428   \n",
       "4                     21.03           21.529056           14.842428   \n",
       "...                     ...                 ...                 ...   \n",
       "17515                 21.18           28.244204           17.224575   \n",
       "17516                 21.18           28.244204           17.224575   \n",
       "17517                 21.18           28.244204           17.224575   \n",
       "17518                 21.18           28.244204           17.224575   \n",
       "17519                 21.18           28.244204           17.224575   \n",
       "\n",
       "       Cross_Section_Sto_Nino  Cross_Section_Montalban  Velocity_Sto_Nino  \\\n",
       "0                      803.88                    630.9           0.026165   \n",
       "1                      804.54                    630.9           0.026450   \n",
       "2                      804.54                    630.9           0.026450   \n",
       "3                      805.20                    630.9           0.026738   \n",
       "4                      805.20                    630.9           0.026738   \n",
       "...                       ...                      ...                ...   \n",
       "17515                  821.04                    635.4           0.034401   \n",
       "17516                  821.04                    635.4           0.034401   \n",
       "17517                  821.04                    635.4           0.034401   \n",
       "17518                  821.04                    635.4           0.034401   \n",
       "17519                  821.04                    635.4           0.034401   \n",
       "\n",
       "       Velocity_Montalban             datetime           t      x  \n",
       "0                0.023526  2016-01-01 00:00:00         0.0  14420  \n",
       "1                0.023526  2016-01-01 01:00:00      3600.0  14420  \n",
       "2                0.023526  2016-01-01 02:00:00      7200.0  14420  \n",
       "3                0.023526  2016-01-01 03:00:00     10800.0  14420  \n",
       "4                0.023526  2016-01-01 04:00:00     14400.0  14420  \n",
       "...                   ...                  ...         ...    ...  \n",
       "17515            0.027108  2017-12-31 19:00:00  63140400.0  14420  \n",
       "17516            0.027108  2017-12-31 20:00:00  63144000.0  14420  \n",
       "17517            0.027108  2017-12-31 21:00:00  63147600.0  14420  \n",
       "17518            0.027108  2017-12-31 22:00:00  63151200.0  14420  \n",
       "17519            0.027108  2017-12-31 23:00:00  63154800.0  14420  \n",
       "\n",
       "[17520 rows x 18 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016_2017 = pd.read_csv(\"compiled_data_2016_2017.csv\")\n",
    "df_2016_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_2017['friction_coeff'] = [0.033 for i in range(len(df_2016_2017))]\n",
    "df_2016_2017['slope'] = [1/1500 for i in range(len(df_2016_2017))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mape</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_nse</th>\n",
       "      <th>val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.099256</td>\n",
       "      <td>169.41922</td>\n",
       "      <td>0.112623</td>\n",
       "      <td>0.049607</td>\n",
       "      <td>0.998702</td>\n",
       "      <td>1.323572e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n1  n2  n3 epochs  val_loss   val_mape   val_mae   val_mse   val_nse  \\\n",
       "0  64  64  64     10  0.099256  169.41922  0.112623  0.049607  0.998702   \n",
       "\n",
       "         val_r2  \n",
       "0  1.323572e-12  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Rainfall_Aries</th>\n",
       "      <th>Rainfall_Boso</th>\n",
       "      <th>Rainfall_Campana</th>\n",
       "      <th>Rainfall_Nangka</th>\n",
       "      <th>Rainfall_Oro</th>\n",
       "      <th>Waterlevel_Sto_Nino</th>\n",
       "      <th>Waterlevel_Montalban</th>\n",
       "      <th>Discharge_Sto_Nino</th>\n",
       "      <th>Discharge_San_Jose</th>\n",
       "      <th>Cross_Section_Sto_Nino</th>\n",
       "      <th>Cross_Section_Montalban</th>\n",
       "      <th>Velocity_Sto_Nino</th>\n",
       "      <th>Velocity_Montalban</th>\n",
       "      <th>datetime</th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>friction_coeff</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.18</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.033407</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>803.88</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026165</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.280072</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>804.54</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.19</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.280072</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>804.54</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.529056</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>805.20</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>21.03</td>\n",
       "      <td>21.529056</td>\n",
       "      <td>14.842428</td>\n",
       "      <td>805.20</td>\n",
       "      <td>630.9</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>17515</td>\n",
       "      <td>16059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 19:00:00</td>\n",
       "      <td>63140400.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17516</th>\n",
       "      <td>17516</td>\n",
       "      <td>16424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>63144000.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17517</th>\n",
       "      <td>17517</td>\n",
       "      <td>16789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>63147600.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17518</th>\n",
       "      <td>17518</td>\n",
       "      <td>17154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>63151200.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17519</th>\n",
       "      <td>17519</td>\n",
       "      <td>17519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>21.18</td>\n",
       "      <td>28.244204</td>\n",
       "      <td>17.224575</td>\n",
       "      <td>821.04</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>63154800.0</td>\n",
       "      <td>14420</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index  Rainfall_Aries  Rainfall_Boso  Rainfall_Campana  \\\n",
       "0               0      0               0              1                 2   \n",
       "1               1      1               0              1                 1   \n",
       "2               2      2               1              1                 1   \n",
       "3               3      3               0              0                 0   \n",
       "4               4      4               1              1                 1   \n",
       "...           ...    ...             ...            ...               ...   \n",
       "17515       17515  16059               0              0                 0   \n",
       "17516       17516  16424               0              0                 0   \n",
       "17517       17517  16789               0              0                 0   \n",
       "17518       17518  17154               0              0                 0   \n",
       "17519       17519  17519               0              0                 0   \n",
       "\n",
       "       Rainfall_Nangka  Rainfall_Oro  Waterlevel_Sto_Nino  \\\n",
       "0                    0             0                12.18   \n",
       "1                    1             0                12.19   \n",
       "2                    0             1                12.19   \n",
       "3                    1             0                12.20   \n",
       "4                    0             0                12.20   \n",
       "...                ...           ...                  ...   \n",
       "17515                0             0                12.44   \n",
       "17516                0             0                12.44   \n",
       "17517                0             0                12.44   \n",
       "17518                0             0                12.44   \n",
       "17519                0             0                12.44   \n",
       "\n",
       "       Waterlevel_Montalban  Discharge_Sto_Nino  Discharge_San_Jose  \\\n",
       "0                     21.03           21.033407           14.842428   \n",
       "1                     21.03           21.280072           14.842428   \n",
       "2                     21.03           21.280072           14.842428   \n",
       "3                     21.03           21.529056           14.842428   \n",
       "4                     21.03           21.529056           14.842428   \n",
       "...                     ...                 ...                 ...   \n",
       "17515                 21.18           28.244204           17.224575   \n",
       "17516                 21.18           28.244204           17.224575   \n",
       "17517                 21.18           28.244204           17.224575   \n",
       "17518                 21.18           28.244204           17.224575   \n",
       "17519                 21.18           28.244204           17.224575   \n",
       "\n",
       "       Cross_Section_Sto_Nino  Cross_Section_Montalban  Velocity_Sto_Nino  \\\n",
       "0                      803.88                    630.9           0.026165   \n",
       "1                      804.54                    630.9           0.026450   \n",
       "2                      804.54                    630.9           0.026450   \n",
       "3                      805.20                    630.9           0.026738   \n",
       "4                      805.20                    630.9           0.026738   \n",
       "...                       ...                      ...                ...   \n",
       "17515                  821.04                    635.4           0.034401   \n",
       "17516                  821.04                    635.4           0.034401   \n",
       "17517                  821.04                    635.4           0.034401   \n",
       "17518                  821.04                    635.4           0.034401   \n",
       "17519                  821.04                    635.4           0.034401   \n",
       "\n",
       "       Velocity_Montalban             datetime           t      x  \\\n",
       "0                0.023526  2016-01-01 00:00:00         0.0  14420   \n",
       "1                0.023526  2016-01-01 01:00:00      3600.0  14420   \n",
       "2                0.023526  2016-01-01 02:00:00      7200.0  14420   \n",
       "3                0.023526  2016-01-01 03:00:00     10800.0  14420   \n",
       "4                0.023526  2016-01-01 04:00:00     14400.0  14420   \n",
       "...                   ...                  ...         ...    ...   \n",
       "17515            0.027108  2017-12-31 19:00:00  63140400.0  14420   \n",
       "17516            0.027108  2017-12-31 20:00:00  63144000.0  14420   \n",
       "17517            0.027108  2017-12-31 21:00:00  63147600.0  14420   \n",
       "17518            0.027108  2017-12-31 22:00:00  63151200.0  14420   \n",
       "17519            0.027108  2017-12-31 23:00:00  63154800.0  14420   \n",
       "\n",
       "       friction_coeff     slope  \n",
       "0               0.033  0.000667  \n",
       "1               0.033  0.000667  \n",
       "2               0.033  0.000667  \n",
       "3               0.033  0.000667  \n",
       "4               0.033  0.000667  \n",
       "...               ...       ...  \n",
       "17515           0.033  0.000667  \n",
       "17516           0.033  0.000667  \n",
       "17517           0.033  0.000667  \n",
       "17518           0.033  0.000667  \n",
       "17519           0.033  0.000667  \n",
       "\n",
       "[17520 rows x 20 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split = int(0.50*len(df_2016_2017))\n",
    "#split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_neurons = [16,32,64]   ######## Check the number of neurons ########\n",
    "layer_2_neurons = [16,32,64]  ######## Check the number of neurons ########\n",
    "layer_3_neurons = [16,32,64]  ######## Check the number of neurons ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2016_2017 = df_2016_2017[:int(0.50*len(df_2016_2017))]\n",
    "val_2016_2017 = df_2016_2017[int(0.50*len(df_2016_2017)):int(0.75*len(df_2016_2017))]\n",
    "test_2016_2017 = df_2016_2017[int(0.75*len(df_2016_2017)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2016_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2016_2017 = np.array(train_2016_2017[['x','t', 'Discharge_Sto_Nino', 'friction_coeff', 'slope', 'Rainfall_Aries', 'Rainfall_Boso', 'Rainfall_Campana', 'Rainfall_Nangka', 'Rainfall_Oro']].values.tolist())\n",
    "X_val_2016_2017 = np.array(val_2016_2017[['x','t', 'Discharge_Sto_Nino', 'friction_coeff', 'slope', 'Rainfall_Aries', 'Rainfall_Boso', 'Rainfall_Campana', 'Rainfall_Nangka', 'Rainfall_Oro']].values.tolist())\n",
    "X_test_2016_2017 = np.array(test_2016_2017[['x','t', 'Discharge_Sto_Nino', 'friction_coeff', 'slope', 'Rainfall_Aries', 'Rainfall_Boso', 'Rainfall_Campana', 'Rainfall_Nangka', 'Rainfall_Oro']].values.tolist())\n",
    "Y_train_2016_2017 = np.array(train_2016_2017[['Velocity_Sto_Nino','Waterlevel_Sto_Nino']].values.tolist())\n",
    "Y_val_2016_2017 = np.array(val_2016_2017[['Velocity_Sto_Nino','Waterlevel_Sto_Nino']].values.tolist())\n",
    "Y_test_2016_2017 = np.array(test_2016_2017[['Velocity_Sto_Nino','Waterlevel_Sto_Nino']].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2016_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n1, n2, n3, reg):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, activation='relu', kernel_regularizer=l2(reg), input_shape=(5,)))\n",
    "    model.add(Dense(n2, activation='relu', kernel_regularizer=l2(reg)))\n",
    "    model.add(Dense(n3, activation='relu', kernel_regularizer=l2(reg)))\n",
    "    model.add(Dense(2))\n",
    "    \n",
    "    # Create input tensor\n",
    "    input_tensor = Input(shape=(5,))\n",
    "    \n",
    "    # Get output tensor by calling the model on the input tensor\n",
    "    output_tensor = model(input_tensor)\n",
    "    \n",
    "    # Calculate gradients within the same graph\n",
    "    grads_u = K.gradients(output_tensor[:,0], input_tensor)[0]\n",
    "    grads_h = K.gradients(output_tensor[:,1], input_tensor)[0]\n",
    "    du_dx, du_dt, dh_dx = grads_u[:,0], grads_u[:,1], grads_h[:,0]\n",
    "    calc_grads_inputs = K.stack((du_dx, du_dt, dh_dx, input_tensor[:,3], input_tensor[:,4]), axis=1)\n",
    "    \n",
    "    # Create new model that includes gradient computation\n",
    "    full_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    \n",
    "    # Compile with custom loss that uses calc_grads_inputs\n",
    "    full_model.compile(optimizer='adam', \n",
    "                      loss=[custom_loss(calc_grads_inputs)], \n",
    "                      metrics=['mape', 'mae', 'mse', NSE, r_square])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for reg in reg_consts:\n",
    "    for n1 in layer_1_neurons:\n",
    "        for n2 in layer_2_neurons:\n",
    "            for n3 in layer_3_neurons:\n",
    "                print(n1,n2,n3,reg)\n",
    "                K.clear_session()\n",
    "                \n",
    "                model = create_model(n1,n2,n3,reg)\n",
    "                early_stopping_monitor = EarlyStopping(patience = 2, verbose=False)\n",
    "                history = model.fit(X_train_2016_2017,Y_train_2016_2017, epochs=epochs, batch_size=32, validation_data=(X_val_2016_2017,Y_val_2016_2017), callbacks=[early_stopping_monitor])\n",
    "                \n",
    "                # Saving results\n",
    "                val_loss = history.history['val_loss'][-1]\n",
    "                val_mae = history.history['val_mae'][-1]\n",
    "                val_mse = history.history['val_mse'][-1]\n",
    "                val_mape = history.history['val_mape'][-1]\n",
    "                val_nse = history.history['val_NSE'][-1]\n",
    "                val_r_square = history.history['val_r_square'][-1]\n",
    "                \n",
    "                \n",
    "                results = pd.DataFrame(columns=['n1','n2','n3', 'epochs', 'reg',\n",
    "                               'val_r2', 'val_nse', 'val_mse', 'val_mae', 'val_mape'])\n",
    "                \n",
    "                # Create a new row as a DataFrame\n",
    "                new_row = pd.DataFrame({\n",
    "                    'n1': [n1],\n",
    "                    'n2': [n2],\n",
    "                    'n3': [n3], \n",
    "                    'epochs': [len(history.history['val_loss'])],\n",
    "                    'reg': [reg],\n",
    "                    'val_r2': [val_r_square], \n",
    "                    'val_nse': [val_nse], \n",
    "                    'val_mse': [val_mse], \n",
    "                    'val_loss': [val_loss],\n",
    "                    'val_mae': [val_mae], \n",
    "                    'val_mape': [val_mape]\n",
    "                })\n",
    "                \n",
    "                # Concatenate the new row with the existing results\n",
    "                results = pd.concat([results, new_row], ignore_index=True)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "                    best_n1 = n1\n",
    "                    best_n2 = n2\n",
    "                    best_n3 = n3\n",
    "                    best_reg = reg\n",
    "                    best_history = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Mahesh Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for reg in reg_consts:\n",
    "    for n1 in layer_1_neurons:\n",
    "        for n2 in layer_2_neurons:\n",
    "            for n3 in layer_3_neurons:\n",
    "                print(n1,n2,n3,reg)\n",
    "                K.clear_session()\n",
    "                model = Sequential()\n",
    "                model.add(Dense(n1, activation = 'relu', kernel_regularizer=l2(reg),input_shape = (5,)))\n",
    "                model.add(Dense(n2, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "                model.add(Dense(n3, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "\n",
    "                model.add(Dense(2))\n",
    "                grads_u = K.gradients(model.output[:,0], model.input)[0]\n",
    "                grads_h = K.gradients(model.output[:,1], model.input)[0]\n",
    "\n",
    "\n",
    "                du_dx, du_dt, dh_dx = grads_u[:,0],grads_u[:,1],grads_h[:,0]\n",
    "                calc_grads_inputs = K.stack((du_dx, du_dt, dh_dx, model.input[:,3],model.input[:,4]), axis=1)\n",
    "                # model.summary()\n",
    "                #Compile the model\n",
    "                model.compile(optimizer = 'adam', loss = [custom_loss(calc_grads_inputs)], metrics=['mape', 'mae', 'mse',NSE, r_square])\n",
    "                #fit the model\n",
    "                early_stopping_monitor = EarlyStopping(patience = 2, verbose=False)\n",
    "                history = model.fit(X_train_2016_2017,Y_train_2016_2017, epochs=epochs, batch_size=128, validation_data=(X_val_2016_2017,Y_val_2016_2017), callbacks=[early_stopping_monitor])\n",
    "\n",
    "                # Saving results\n",
    "                val_loss = history.history['val_loss'][-1]\n",
    "                val_mae = history.history['val_mae'][-1]\n",
    "                val_mse = history.history['val_mse'][-1]\n",
    "                val_mape = history.history['val_mape'][-1]\n",
    "                val_nse = history.history['val_NSE'][-1]\n",
    "                val_r_square = history.history['val_r_square'][-1]\n",
    "\n",
    "                results.append({\n",
    "                    'n1':n1,\n",
    "                    'n2':n2,\n",
    "                    'n3':n3, \n",
    "                    'epochs':len(history.history['val_loss']), \n",
    "                    'reg':reg,\n",
    "                    'val_r2':val_r_square, \n",
    "                    'val_nse':val_nse, \n",
    "                    'val_mse':val_mse, \n",
    "                    'val_loss':val_loss,\n",
    "                    'val_mae':val_mae, \n",
    "                    'val_mape':val_mape\n",
    "                })\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "                    best_n1 = n1\n",
    "                    best_n2 = n2\n",
    "                    best_n3 = n3\n",
    "                    best_reg = reg\n",
    "                    best_history = history\n",
    "                    #model.save(save_model_path)\n",
    "                    #results.to_csv(save_results_path)\n",
    "                    \n",
    "#results.to_csv(save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDE Loss Function\n",
    "def custom_loss(grads_inputs):\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = grads_inputs[:,0], grads_inputs[:,1], grads_inputs[:,2], grads_inputs[:,3], grads_inputs[:,4]\n",
    "    g = K.constant(9.8)\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        loss_saint_venant = du_dt + y_pred[:,0] * du_dx + g*dh_dx + g*slope + g*K.square(fric_coeff) * K.square(y_true[:,0])/(K.pow(y_true[:,1], 4/3) + K.epsilon())\n",
    "        l = K.mean(K.square(loss_saint_venant))\n",
    "\n",
    "        return 2*l+ K.sum(K.mean(K.square(y_pred - y_true), axis=0))\n",
    "   \n",
    "    # Return a function\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Dense(n1, activation = 'relu', input_shape = (1,)))\n",
    "model.add(Dense(n1, activation = 'relu', kernel_regularizer=l2(reg),input_shape = (5,)))\n",
    "model.add(Dense(n2, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "model.add(Dense(n3, activation = 'relu', kernel_regularizer=l2(reg)))\n",
    "\n",
    "model.add(Dense(2))\n",
    "grads_u = K.gradients(model.output[:,0], model.input)[0]\n",
    "grads_h = K.gradients(model.output[:,1], model.input)[0]\n",
    "\n",
    "\n",
    "du_dx, du_dt, dh_dx = grads_u[:,0],grads_u[:,1],grads_h[:,0]\n",
    "calc_grads_inputs = K.stack((du_dx, du_dt, dh_dx, model.input[:,3],model.input[:,4]), axis=1)\n",
    "# model.summary()\n",
    "#Compile the model\n",
    "model.compile(optimizer = 'adam', loss = [custom_loss(calc_grads_inputs)], metrics=['mape', 'mae', 'mse',NSE, r_square])\n",
    "#fit the model\n",
    "early_stopping_monitor = EarlyStopping(patience = 2, verbose=False)\n",
    "history = model.fit(X_train,Y_train, epochs=epochs, batch_size=128, validation_data=(X_val,Y_val), callbacks=[early_stopping_monitor])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_test_2016_2017, Y_test_2016_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''\n",
    "def normalize_data(X_train, X_val, Y_train, Y_val):\n",
    "    \"\"\"Normalize input and output data\"\"\"\n",
    "    X_mean = np.mean(X_train, axis=0)\n",
    "    X_std = np.std(X_train, axis=0)\n",
    "    Y_mean = np.mean(Y_train, axis=0)\n",
    "    Y_std = np.std(Y_train, axis=0)\n",
    "    \n",
    "    X_train_norm = (X_train - X_mean) / (X_std + 1e-8)\n",
    "    X_val_norm = (X_val - X_mean) / (X_std + 1e-8)\n",
    "    Y_train_norm = (Y_train - Y_mean) / (Y_std + 1e-8)\n",
    "    Y_val_norm = (Y_val - Y_mean) / (Y_std + 1e-8)\n",
    "    \n",
    "    return (X_train_norm, X_val_norm, Y_train_norm, Y_val_norm, \n",
    "            X_mean, X_std, Y_mean, Y_std)\n",
    "'''\n",
    "def custom_loss(grads_inputs, physics_weight=1.0):\n",
    "    \"\"\"Modified loss function with adjustable physics weight and improved numerical stability\"\"\"\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = (grads_inputs[:,i] for i in range(5))\n",
    "    g = K.constant(9.81)  # More precise gravity constant\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        # Data loss\n",
    "        mse_loss = K.mean(K.square(y_pred - y_true), axis=0)\n",
    "        data_loss = K.sum(mse_loss)\n",
    "        \n",
    "        # Physics loss with improved numerical stability\n",
    "        u = y_pred[:,0]  # velocity\n",
    "        h = y_pred[:,1]  # water level\n",
    "        \n",
    "        # Saint-Venant equation terms\n",
    "        momentum_eq = (\n",
    "            du_dt +                                         # ∂u/∂t\n",
    "            u * du_dx +                                     # u∂u/∂x\n",
    "            g * dh_dx +                                     # g∂h/∂x\n",
    "            g * slope +                                     # gS₀\n",
    "            g * K.square(fric_coeff) * K.square(u) /       # gn²u²/h^(4/3)\n",
    "            (K.pow(K.maximum(h, K.epsilon()), 4/3) + K.epsilon())\n",
    "        )\n",
    "        \n",
    "        physics_loss = K.mean(K.square(momentum_eq))\n",
    "        \n",
    "        # Combined loss with weighting\n",
    "        return data_loss + physics_weight * physics_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def create_pinn_model(input_dim, n1, n2, n3, reg_const):\n",
    "    \"\"\"Create PINN model with improved architecture\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(n1, activation='tanh', input_shape=(input_dim,)),\n",
    "        Dense(n2, activation='tanh'),\n",
    "        Dense(n3, activation='tanh'),\n",
    "        Dense(2, activation='linear')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_pinn(X_train, Y_train, X_val, Y_val, n1=64, n2=32, n3=16, \n",
    "               reg_const=0, physics_weight=1.0, epochs=20, \n",
    "               batch_size=32, patience=2):\n",
    "    \"\"\"Train PINN with improved training process\"\"\"\n",
    "    \n",
    "    '''\n",
    "    # Normalize data\n",
    "    (X_train_norm, X_val_norm, Y_train_norm, Y_val_norm,\n",
    "     X_mean, X_std, Y_mean, Y_std) = normalize_data(X_train, X_val, Y_train, Y_val)\n",
    "    '''\n",
    "    # Create and compile model\n",
    "    model = create_pinn_model(X_train.shape[1], n1, n2, n3, reg_const)\n",
    "    \n",
    "    # Calculate gradients for physics loss\n",
    "    grads_u = K.gradients(model.output[:,0], model.input)[0]\n",
    "    grads_h = K.gradients(model.output[:,1], model.input)[0]\n",
    "    du_dx, du_dt, dh_dx = grads_u[:,0], grads_u[:,1], grads_h[:,0]\n",
    "    calc_grads_inputs = K.stack(\n",
    "        (du_dx, du_dt, dh_dx, model.input[:,3], model.input[:,4]), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Compile with custom loss\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=custom_loss(calc_grads_inputs, physics_weight),\n",
    "        metrics=['mape', 'mae', 'mse', NSE, r_square]\n",
    "    )\n",
    "    \n",
    "    # Train with early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    loss, mape, mae, mse, nse, r2 = model.evaluate(X_val, Y_val)\n",
    "    print(f'Validation Loss: {loss:.4f}')\n",
    "    print(f'Validation MAPE: {mape:.4f}')\n",
    "    print(f'Validation MAE: {mae:.4f}') \n",
    "    print(f'Validation MSE: {mse:.4f}')\n",
    "    print(f'Validation NSE: {nse:.4f}')\n",
    "    print(f'Validation R-squared: {r2:.4f}')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def hyperparameter_tuning(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    # Define hyperparameter ranges\n",
    "    layer_1_neurons = [64]\n",
    "    layer_2_neurons = [64]\n",
    "    layer_3_neurons = [64]\n",
    "    reg_const = 0\n",
    "    physics_weight = 1.0\n",
    "    \n",
    "    # Initialize results tracking\n",
    "    results = pd.DataFrame(columns=[\n",
    "        'n1', 'n2', 'n3', \n",
    "        'epochs', 'val_loss', 'val_mape', 'val_mae', \n",
    "        'val_mse', 'val_nse', 'val_r2'\n",
    "    ])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    \n",
    "    # Grid search\n",
    "    for n1 in layer_1_neurons:\n",
    "        for n2 in layer_2_neurons:\n",
    "            for n3 in layer_3_neurons:\n",
    "                print(f\"\\nTrying parameters: n1={n1}, n2={n2}, n3={n3}\")\n",
    "                # Clear previous model from memory\n",
    "                K.clear_session()\n",
    "\n",
    "                try:\n",
    "                    # Train model with current parameters\n",
    "                    model, history = train_pinn(\n",
    "                        X_train, Y_train,\n",
    "                        X_val, Y_val,\n",
    "                        n1=n1, n2=n2, n3=n3,\n",
    "                        reg_const=reg_const,\n",
    "                        physics_weight=physics_weight,\n",
    "                        epochs=20,\n",
    "                        batch_size=32,\n",
    "                        patience=2\n",
    "                    )\n",
    "\n",
    "                    # Evaluate model\n",
    "                    val_metrics = model.evaluate(X_val, Y_val, verbose=0)\n",
    "                    val_loss = val_metrics[0]\n",
    "\n",
    "                    # Store results\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'n1': [n1],\n",
    "                        'n2': [n2],\n",
    "                        'n3': [n3],\n",
    "                        'epochs': [len(history.history['loss'])],\n",
    "                        'val_loss': [val_metrics[0]],\n",
    "                        'val_mape': [val_metrics[1]],\n",
    "                        'val_mae': [val_metrics[2]],\n",
    "                        'val_mse': [val_metrics[3]],\n",
    "                        'val_nse': [val_metrics[4]],\n",
    "                        'val_r2': [val_metrics[5]]\n",
    "                    })\n",
    "\n",
    "                    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "                    # Update best model if current one is better\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_model = model\n",
    "                        best_params = {\n",
    "                            'n1': n1,\n",
    "                            'n2': n2,\n",
    "                            'n3': n3\n",
    "                        }\n",
    "\n",
    "                    # Save intermediate results\n",
    "                    results.to_csv('hyperparameter_search_results.csv', index=False)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with parameters: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # Print best parameters and their performance\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    \n",
    "    return best_model, results, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "best_model, results, best_params = hyperparameter_tuning(\n",
    "        X_train_2016_2017, Y_train_2016_2017, X_val_2016_2017, Y_val_2016_2017, X_test_2016_2017, Y_test_2016_2017\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_pinn(X_train_2016_2017, Y_train_2016_2017, X_val_2016_2017, Y_val_2016_2017, n1=64, n2=64, n3=64, \n",
    "               reg_const=0, physics_weight=1.0, epochs=20, \n",
    "               batch_size=32, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_2016_2017, Y_test_2016_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using LSTM for the PINNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def custom_loss(grads_inputs, physics_weight=1.0):\n",
    "    \"\"\"Modified loss function with adjustable physics weight and improved numerical stability\"\"\"\n",
    "    du_dx, du_dt, dh_dx, fric_coeff, slope = (grads_inputs[:,i] for i in range(5))\n",
    "    g = K.constant(9.81)  # More precise gravity constant\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        # Data loss\n",
    "        mse_loss = K.mean(K.square(y_pred - y_true), axis=0)\n",
    "        data_loss = K.sum(mse_loss)\n",
    "        \n",
    "        # Physics loss with improved numerical stability\n",
    "        u = y_pred[:,0]  # velocity\n",
    "        h = y_pred[:,1]  # water level\n",
    "        \n",
    "        # Saint-Venant equation terms\n",
    "        momentum_eq = (\n",
    "            du_dt +                                         # ∂u/∂t\n",
    "            u * du_dx +                                     # u∂u/∂x\n",
    "            g * dh_dx +                                     # g∂h/∂x\n",
    "            g * slope +                                     # gS₀\n",
    "            g * K.square(fric_coeff) * K.square(u) /       # gn²u²/h^(4/3)\n",
    "            (K.pow(K.maximum(h, K.epsilon()), 4/3) + K.epsilon())\n",
    "        )\n",
    "        \n",
    "        physics_loss = K.mean(K.square(momentum_eq))\n",
    "        \n",
    "        # Combined loss with weighting\n",
    "        return data_loss + physics_weight * physics_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def create_pinn_model(X_train, X_val, n1, n2, n3, reg_const):\n",
    "    \"\"\"Create PINN model with improved architecture\"\"\"\n",
    "        \n",
    "        \n",
    "    lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((1, 10), input_shape=(10,)),  # Reshape to 3D\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Flatten(),  # Add Flatten layer to handle dimension mismatch\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=2)\n",
    "    ])\n",
    "\n",
    "    return lstm_model\n",
    "\n",
    "def train_pinn(X_train, Y_train, X_val, Y_val, n1=64, n2=64, n3=64, \n",
    "               reg_const=0, physics_weight=1.0, epochs=20, \n",
    "               batch_size=32, patience=2):\n",
    "    \"\"\"Train PINN with improved training process\"\"\"\n",
    "    \n",
    "    '''\n",
    "    # Normalize data\n",
    "    (X_train_norm, X_val_norm, Y_train_norm, Y_val_norm,\n",
    "     X_mean, X_std, Y_mean, Y_std) = normalize_data(X_train, X_val, Y_train, Y_val)\n",
    "    '''\n",
    "    # Create and compile model\n",
    "    model = create_pinn_model(X_train, X_val,n1, n2, n3, reg_const)\n",
    "    \n",
    "    # Calculate gradients for physics loss\n",
    "    grads_u = K.gradients(model.output[:,0], model.input)[0]\n",
    "    grads_h = K.gradients(model.output[:,1], model.input)[0]\n",
    "    du_dx, du_dt, dh_dx = grads_u[:,0], grads_u[:,1], grads_h[:,0]\n",
    "    calc_grads_inputs = K.stack(\n",
    "        (du_dx, du_dt, dh_dx, model.input[:,3], model.input[:,4]), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Compile with custom loss\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=custom_loss(calc_grads_inputs, physics_weight),\n",
    "        metrics=['mape', 'mae', 'mse', NSE, r_square]\n",
    "    )\n",
    "    \n",
    "    # Train with early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    loss, mape, mae, mse, nse, r2 = model.evaluate(X_val, Y_val)\n",
    "    print(f'Validation Loss: {loss:.4f}')\n",
    "    print(f'Validation MAPE: {mape:.4f}')\n",
    "    print(f'Validation MAE: {mae:.4f}') \n",
    "    print(f'Validation MSE: {mse:.4f}')\n",
    "    print(f'Validation NSE: {nse:.4f}')\n",
    "    print(f'Validation R-squared: {r2:.4f}')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8760 samples, validate on 4380 samples\n",
      "Epoch 1/20\n",
      "8640/8760 [============================>.] - ETA: 0s - loss: 21670.0711 - mape: 218.0103 - mae: 5.9490 - mse: 69.9231 - NSE: -0.8222 - r_square: 5.1080e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeremy tan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8760/8760 [==============================] - 5s 613us/sample - loss: 21374.7909 - mape: 218.6895 - mae: 5.9416 - mse: 69.7503 - NSE: -0.8173 - r_square: 5.1530e-04 - val_loss: 103.5557 - val_mape: 297.5153 - val_mae: 5.1365 - val_mse: 51.7778 - val_NSE: -0.4527 - val_r_square: 7.4921e-08\n",
      "Epoch 2/20\n",
      "8760/8760 [==============================] - 2s 184us/sample - loss: 26.1927 - mape: 62.0136 - mae: 1.6634 - mse: 13.0963 - NSE: 0.6585 - r_square: 0.0021 - val_loss: 0.3583 - val_mape: 108.2169 - val_mae: 0.2941 - val_mse: 0.1791 - val_NSE: 0.9950 - val_r_square: 1.0724e-06\n",
      "Epoch 3/20\n",
      "8760/8760 [==============================] - 2s 173us/sample - loss: 0.4579 - mape: 42.0568 - mae: 0.2670 - mse: 0.2289 - NSE: 0.9941 - r_square: 5.4291e-04 - val_loss: 0.2420 - val_mape: 89.7797 - val_mae: 0.2482 - val_mse: 0.1210 - val_NSE: 0.9966 - val_r_square: 2.6195e-11\n",
      "Epoch 4/20\n",
      "8760/8760 [==============================] - 2s 179us/sample - loss: 0.4567 - mape: 41.9696 - mae: 0.2664 - mse: 0.2283 - NSE: 0.9941 - r_square: 4.4565e-04 - val_loss: 0.3351 - val_mape: 90.4879 - val_mae: 0.2831 - val_mse: 0.1675 - val_NSE: 0.9953 - val_r_square: 1.1498e-11\n",
      "Epoch 5/20\n",
      "8760/8760 [==============================] - 2s 282us/sample - loss: 0.4562 - mape: 41.5717 - mae: 0.2662 - mse: 0.2281 - NSE: 0.9941 - r_square: 5.6451e-04 - val_loss: 0.2892 - val_mape: 88.6704 - val_mae: 0.2665 - val_mse: 0.1446 - val_NSE: 0.9959 - val_r_square: 1.3771e-06\n",
      "Validation Loss: 0.2420\n",
      "Validation MAPE: 89.7797\n",
      "Validation MAE: 0.2482\n",
      "Validation MSE: 0.1210\n",
      "Validation NSE: 0.9965\n",
      "Validation R-squared: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model, history = train_pinn(\n",
    "                        X_train_2016_2017, Y_train_2016_2017, X_val_2016_2017, Y_val_2016_2017,\n",
    "                        epochs=20,\n",
    "                        batch_size=32,\n",
    "                        patience=2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3859772109503105, 30.770645, 0.2092242, 0.1929672, 0.9956889, 9.617839e-10]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_2016_2017, Y_test_2016_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
